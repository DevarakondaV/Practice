{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Regression Models\n",
    "#Chapter 3\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temp Functions to be deleted\n",
    "#plots heat map of multi_gauss\n",
    "def plot_multi_gauss(x,y,mu,covar):\n",
    "    nbins = 50\n",
    "    xx,yy = np.mgrid[x.min():x.max():nbins*1j,y.min():y.max():nbins*1j]\n",
    "    xxyy = np.vstack([xx.flatten(), yy.flatten()]).T\n",
    "    zz = multi_gauss(xxyy,mu,covar)\n",
    "    plt.pcolormesh(xx,yy,zz.reshape(xx.shape))\n",
    "    plt.show()\n",
    "    \n",
    "#multi gauss\n",
    "def multi_gauss(x,mu,cov):\n",
    "    D = len(mu)\n",
    "    a = 1.0/(np.power(2*np.pi,D/2.0))\n",
    "\n",
    "    b = 1.0/(np.power(np.linalg.det(cov),.5))\n",
    "\n",
    "    c = np.exp((-.5)*(maha_dist(x,mu,cov)))\n",
    "    return a*b*c\n",
    "\n",
    "#mahalanobis dist\n",
    "def maha_dist(x,mu,cov):\n",
    "    diff = x-mu\n",
    "    ret = np.matmul(diff,np.linalg.inv(cov))\n",
    "    ret = np.matmul(ret,diff.T)\n",
    "    return ret.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sin(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "def cos(x):\n",
    "    return np.cos(x)\n",
    "\n",
    "def pw(x,n):\n",
    "    return np.power(x,n)\n",
    "\n",
    "def gauss_sample(m,s):\n",
    "    return np.random.normal(m,s)\n",
    "\n",
    "def Y(x,m,b):\n",
    "    return (m*x)+b\n",
    "\n",
    "def nlin_fun(x):\n",
    "    y = (10*sin(x))+Y(x,0.2,-.5)-(3*cos(2*x))\n",
    "    return y\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_basis(x,mu,s):\n",
    "    N = len(mu)\n",
    "    x = np.outer(np.transpose(x),np.ones(N))\n",
    "    diff = np.subtract(x,mu)\n",
    "    return sigmoid((1.0/s)*diff)\n",
    "\n",
    "def gauss_basis(x,mu,s):\n",
    "    N = len(mu)\n",
    "    x = np.outer(np.transpose(x),np.ones(N))\n",
    "    diff = np.subtract(x,mu)\n",
    "    n = np.power(diff,2)\n",
    "    d = 2*np.power(s,2)\n",
    "    f = (1.0/d)*n\n",
    "    return np.exp(-f)\n",
    "\n",
    "def poly_basis(x,deg):\n",
    "    if (deg == 0):\n",
    "        return np.zeros(len(x)).reshape(len(x),1)\n",
    "    x = np.outer(np.transpose(x),np.ones(deg))\n",
    "    return np.power(x,np.arange(1,deg+1,1))\n",
    "\n",
    "#returns wegihts based on zero mean gaussian\n",
    "def get_weights(numb):\n",
    "    return np.random.normal(0,.5,numb)\n",
    "\n",
    "def get_centers(x,n_bfun):\n",
    "    if len(x) == 1:\n",
    "        c = np.random.normal(x[0],.3,n_bfun)\n",
    "        return c\n",
    "    if n_bfun == 0:\n",
    "        return []\n",
    "    if n_bfun == 1:\n",
    "        return [np.average(x)]\n",
    "    mi = min(x)\n",
    "    ma = max(x)\n",
    "    delt = (ma-mi)/n_bfun\n",
    "    cen = []\n",
    "    while mi<ma and len(cen)<n_bfun:\n",
    "        cen.append(mi)\n",
    "        mi = mi+delt\n",
    "    \n",
    "    return cen\n",
    "\n",
    "def moore_pen_inv(phi):\n",
    "    m = np.matmul(np.transpose(phi),phi)\n",
    "    m = np.matmul(np.linalg.inv(m),np.transpose(phi))\n",
    "    return m\n",
    "\n",
    "#The approxiamte function y(x,w) given input x\n",
    "#weights and basis functions\n",
    "def approx_y(w,x,c,n_bf,s,p):\n",
    "    b,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.ones(len(x))\n",
    "    g = np.insert(b,0,g,1)\n",
    "    return np.matmul(w,np.transpose(g))\n",
    "\n",
    "\n",
    "#Returns maximum likelihood weights and basis functions\n",
    "#for linear regression\n",
    "#pts is the input points\n",
    "#n_bf is the number of basis functions\n",
    "#s is the spatial component of the basis\n",
    "#v is the type of basis function 1->gauss 2->sigmoid\n",
    "def max_likelihood_lin_reg(pts,n_bf,s,p):\n",
    "    x = pts[:,0]\n",
    "    y = pts[:,1]\n",
    "    \n",
    "    g = np.ones(len(x))\n",
    "    bf,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.insert(bf,0,g,1)\n",
    "    w = np.matmul(moore_pen_inv(g),y)\n",
    "    return w,g,c\n",
    "\n",
    "#Returns maximum likelihood weights and basis functions\n",
    "#for linear regression with regularization term\n",
    "#pts is the input points\n",
    "#n_bf is the number of basis functions\n",
    "#s is the spatial component of the basis\n",
    "#p is the type of basis function 1->gauss 2->sigmoid\n",
    "#rg_fac is the regularization factor \n",
    "def max_likelihood_lin_reg_rg(pts,n_bf,s,p,rg_fac):\n",
    "    x = pts[:,0]\n",
    "    y = pts[:,1]\n",
    "    \n",
    "    #c = get_centers(x,n_bf-1)\n",
    "    g = np.ones(len(x))\n",
    "    bf,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.insert(bf,0,g,1)\n",
    "    shp = np.shape(g)\n",
    "    rg_I = rg_fac*np.eye(shp[1],shp[1],dtype=float)\n",
    "    \n",
    "    #calculating weight vector\n",
    "    a = rg_I+np.matmul(np.transpose(g),g)\n",
    "    b = np.matmul(np.linalg.inv(a),np.transpose(g))\n",
    "    w = np.matmul(b,y) \n",
    "    return w,g,c\n",
    "\n",
    "#Returns basis func\n",
    "def pick_basis(data,n_bf,s,p):\n",
    "    if ((p==1) or (p==2)):\n",
    "        c = get_centers(data,n_bf)\n",
    "        \n",
    "    if (p == 1):\n",
    "        return gauss_basis(data,c,s),c\n",
    "    elif (p==2):\n",
    "        return sigmoid_basis(data,c,s),c\n",
    "    elif (p==3):\n",
    "        return poly_basis(data,n_bf),0\n",
    "    \n",
    "#Parameter Distribution Posterior Estimation\n",
    "#p(w|t,m_0,s_0)\n",
    "def weight_dist_post(data,prior_mean,prior_covariance,noise,n_bf,s,p):\n",
    "    \n",
    "    x = data[:,0]\n",
    "    y = data[:,1]\n",
    "    phi,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.ones(len(x))\n",
    "    phi = np.insert(phi,0,g,1)\n",
    "    \n",
    "    a = noise*np.matmul(np.transpose(phi),phi)\n",
    "    post_cov_inv = np.linalg.inv(prior_covariance)+a\n",
    "    \n",
    "    a = noise*np.matmul(np.transpose(phi),y)\n",
    "    a = np.matmul(np.linalg.inv(prior_covariance),prior_mean)+a\n",
    "    post_mean = np.matmul(np.linalg.inv(post_cov_inv),a)\n",
    "    \n",
    "    return post_mean,np.linalg.inv(post_cov_inv),c\n",
    "\n",
    "#Linear regression on linear function defined by paramteres\n",
    "#m and b\n",
    "def post_weights_linear_example(m,b):\n",
    "    x = np.arange(0,3,.002)\n",
    "    print(\"Len x\",len(x))\n",
    "    print(\"Min x\",min(x))\n",
    "    print(\"Max x\",max(x))\n",
    "    \n",
    "    np.random.shuffle(x)\n",
    "    y = gauss_sample(Y(x,m,b),.3)\n",
    "    pts = np.stack((x,y),axis=1)\n",
    "    \n",
    "    n = 0\n",
    "    s = .5\n",
    "    n_bf = 2\n",
    "    p = 3\n",
    "    m = np.array([1,1])\n",
    "    cov = np.array([[1,3.0/5],[3.0/5,2]])\n",
    "    cen = []\n",
    "    len_x = len(x)\n",
    "    print(len_x)\n",
    "\n",
    "    wx = np.arange(m[0]-2*(.1),(m[0]+2*(.1)),.01)\n",
    "    wy = np.arange(m[1]-2*(.1),(m[1]+2*(.1)),.01)\n",
    "    plot_multi_gauss(wx,wy,m,cov)\n",
    "\n",
    "    while n<(len_x):\n",
    "        m,cov,c = weight_dist_post(pts[n:n+5],m,cov,25,n_bf,s,p)\n",
    "        n = n+5\n",
    "\n",
    "    \n",
    "    ww,gg,cc = max_likelihood_lin_reg(pts,8,s,1)\n",
    "    yy = approx_y(ww,x,cc,8,s,1)\n",
    "    \n",
    "    \n",
    "    print(\"Weights post:\", m)\n",
    "    print(\"Covariance\", cov)\n",
    "    wx = np.arange(m[0]-2*(.1),(m[0]+2*(.1)),.01)\n",
    "    wy = np.arange(m[1]-2*(.1),(m[1]+2*(.1)),.01)\n",
    "    plot_multi_gauss(wx,wy,m,cov)\n",
    "\n",
    "    #def approx_y(w,x,c,s,p):\n",
    "    yyy = Y(x,m[1],m[0])\n",
    "    plt.plot(x,y,'.')\n",
    "    plt.plot(x,yy,'.')\n",
    "    plt.plot(x,yyy,'.')\n",
    "    plt.legend([\"True\",\"Estimate_ML\",\"Estiamte_Post\"])\n",
    "    plt.show()\n",
    "    \n",
    "#Posterior weights distribution non linear function\n",
    "#Example\n",
    "def post_weights_nonlin_example():\n",
    "    x = np.arange(0,2*np.pi,.02)\n",
    "    print(\"Len x\",len(x))\n",
    "    print(\"min x\",min(x))\n",
    "    print(\"max x\",max(x))\n",
    "\n",
    "    np.random.shuffle(x)\n",
    "    y = gauss_sample((10*sin(x))+Y(x,0.2,-.5)-(3*cos(2*x)),.3)\n",
    "    pts = np.stack((x,y),axis=1)\n",
    "\n",
    "\n",
    "    n = 0\n",
    "    s = .5\n",
    "    n_bf = 10\n",
    "    p = 1\n",
    "    m = np.array([1,1,1,1,1,1,1,1,1,1])\n",
    "    cov = np.random.rand(10,10)\n",
    "    cen = []\n",
    "    len_x = len(x)\n",
    "\n",
    "    while n<(len_x):\n",
    "        m,cov,c = weight_dist_post(pts[n:n+20],m,cov,25,n_bf,s,p)\n",
    "        cen.append(c)\n",
    "        n = n+20\n",
    "\n",
    "    \n",
    "    ww,gg,cc = max_likelihood_lin_reg(pts,8,s,1)\n",
    "    yy = approx_y(ww,x,cc,8,s,1)\n",
    "\n",
    "    print(\"Weight Estimates\",  m)\n",
    "\n",
    "    yyy = approx_y(m,x,cen,10,s,1)\n",
    "    plt.plot(x,y,'.')\n",
    "    plt.plot(x,yy,'.')\n",
    "    plt.plot(x,yyy,'.')\n",
    "    plt.legend([\"True\",\"Estimate_ML\",\"Estiamte_Post\"])\n",
    "    plt.show()\n",
    "\n",
    "#Equivalent Kernel Approximation\n",
    "def equivalent_kernel(x,xn,n_bf,cov,noise,s,p):\n",
    "    phi_x,c = pick_basis(x,n_bf-1,s,p)\n",
    "    phi_xn,c = pick_basis(xn,n_bf-1,s,p)\n",
    "    g_x = np.ones(len(x))\n",
    "    g_xn = np.ones(len(xn))\n",
    "    phi_x = np.insert(phi_x,0,g_x,1)\n",
    "    phi_xn = np.insert(phi_xn,0,g_xn,1)\n",
    "    \n",
    "    \n",
    "    a = noise*phi_x\n",
    "    a = np.matmul(a,cov)\n",
    "    a = np.matmul(a,np.transpose(phi_xn))\n",
    "    return a\n",
    "\n",
    "#Evidence Approximation for hyper parameters\n",
    "#p(alpha,beta|t)\n",
    "\n",
    "\n",
    "\n",
    "#Performs a kernel estimation example on a non linear function\n",
    "def kernel_example():\n",
    "    x = np.arange(-2*np.pi,2*np.pi,.01)\n",
    "    np.random.shuffle(x)\n",
    "    y = gauss_sample(nlin_fun(x),1)\n",
    "    #y = gauss_sample(Y(x,5,.3),1)\n",
    "    pts = np.stack((x,y),axis=1)\n",
    "    \n",
    "    n = 0\n",
    "    s = 1\n",
    "    n_bf = 10\n",
    "    m = np.zeros(10)\n",
    "    cov = np.random.rand(10,10)\n",
    "    len_x = len(x)\n",
    "    p=1\n",
    "    \n",
    "    while n<(len_x):\n",
    "        m,cov,c = weight_dist_post(pts[n:n+20],m,cov,25,n_bf,s,p)\n",
    "        n = n+20\n",
    "    \n",
    "    xx = np.arange(-2*np.pi,2*np.pi,.1)\n",
    "    K = equivalent_kernel(xx,x,n_bf,cov,25,s,p)\n",
    "    yy = np.matmul(K,y)\n",
    "    print(np.shape(y))\n",
    "    yyy = approx_y(m,x,0,10,s,p)\n",
    "    plt.plot(x,y,'.')\n",
    "    plt.plot(xx,nlin_fun(xx),'x')\n",
    "    plt.plot(xx,yy,'x')\n",
    "    plt.plot(x,yyy,'.')\n",
    "    plt.legend([\"Train data\",\"True Point\",\"Kernel-Estimate\",\"Weight Estimate\"])\n",
    "    plt.show()\n",
    "    return m,cov,K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[75.9248383539499, 19.30189496280254], [0.0002324826757801808, 22.057734494826523], [0.0006961571176458938, 22.060018327274307], [0.0008954894303909866, 23.757567839344123], [0.0021803513198130633, 23.77904798466408], [0.017857397322946413, 23.789232143423938], [0.09597032748496327, 23.797611586176515], [0.05499172591964488, 23.779538752974585], [0.03695519644439792, 23.6823506781593], [0.021872256272883597, 23.32548896170411]]\n",
      "10247.593375188993\n",
      "8968.296757325175\n",
      "8967.348901188683\n",
      "8326.54388057538\n",
      "8318.766472546573\n",
      "8314.134742512593\n",
      "8306.739884008304\n",
      "8294.223169441693\n",
      "8253.781771263637\n",
      "8117.138846973976\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6b4391fc90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def approx_alpha_beta(x,y,n_bf,s,p,alpha,beta):\n",
    "    phi,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.ones(len(x))\n",
    "    phi = np.insert(phi,0,g,1)\n",
    "    #Guess alpha\n",
    "    #find Mn and gamma\n",
    "    #Then estimate alpha\n",
    "    #repeat until convergence\n",
    "    \n",
    "    n_a = alpha\n",
    "    n_b = beta\n",
    "    \n",
    "    diff_a = 5\n",
    "    diff_b = 5\n",
    "    \n",
    "    r = 0\n",
    "    while(diff_a>.001 or diff_b>.001):\n",
    "        a = beta*np.matmul(np.transpose(phi),phi)\n",
    "        A = alpha*np.eye(np.shape(a)[0])+a\n",
    "        mn = beta*np.matmul(np.linalg.inv(A),np.matmul(np.transpose(phi),y))\n",
    "        e_vals,v = np.linalg.eig(a)\n",
    "        gamma = np.sum(1.0/(e_vals+alpha))\n",
    "        \n",
    "        #a\n",
    "        if (diff_a>.001):\n",
    "            n_a = gamma/(np.matmul(np.transpose(mn),mn))\n",
    "            diff_a = np.absolute(n_a-alpha)\n",
    "            alpha=n_a\n",
    "        \n",
    "        #b\n",
    "        if (diff_b>.001):\n",
    "            diff = y-np.matmul(mn,np.transpose(phi))\n",
    "            #diff = np.power(diff,2)\n",
    "            #diff = np.sum(diff)\n",
    "            diff = np.linalg.norm(diff)\n",
    "            inv_b = (1.0/(len(x)-gamma))*diff\n",
    "            n_b = 1.0/inv_b\n",
    "            diff_b = np.absolute(n_b-beta)\n",
    "            beta=n_b\n",
    "        r=r+1\n",
    "        #print(diff_a,diff_b)\n",
    "    return alpha,beta\n",
    "\n",
    "\n",
    "#Returns the posterior weight distribution\n",
    "#Given new data x and y\n",
    "def weight_dist_zero_mean_prior(pts,prior_m,prior_cov,alpha,beta,n_bf,s,p):\n",
    "    x=  pts[:,0]\n",
    "    y = pts[:,1]\n",
    "    \n",
    "    phi,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.ones(len(x))\n",
    "    phi = np.insert(phi,0,g,1)\n",
    "    \n",
    "    a = beta*np.matmul(np.transpose(phi),phi)\n",
    "    post_cov_inv = alpha*np.eye(np.shape(a)[0])+a\n",
    "    post_m = beta*np.matmul(np.linalg.inv(post_cov_inv),np.matmul(np.transpose(phi),y))\n",
    "    return post_m,np.linalg.inv(post_cov_inv)\n",
    "\n",
    "\n",
    "def evidence_approximation(pts,alpha,beta,n_bf,s,p):\n",
    "    x = pts[:,0]\n",
    "    #y = pts[:,1]\n",
    "    N = 20\n",
    "    M = n_bf\n",
    "    \n",
    "    phi,c = pick_basis(x,n_bf-1,s,p)\n",
    "    g = np.ones(len(x))\n",
    "    phi = np.insert(phi,0,g,1)\n",
    "    \n",
    "    a = beta*np.matmul(np.transpose(phi),phi)\n",
    "    A = alpha*np.eye(np.shape(a)[0])+a\n",
    "    mn = beta*np.matmul(np.linalg.inv(A),np.matmul(np.transpose(phi),y))\n",
    "\n",
    "    Eud = y-np.matmul(phi,mn)\n",
    "    Eud = np.linalg.norm(Eud)\n",
    "    Emn = ((beta/2.0)*np.power(Eud,2))+((alpha/2.0)*np.matmul(np.transpose(mn),mn))\n",
    "    AA = np.power(2*np.pi,M/2.0)*np.power(np.linalg.det(A),-.5)\n",
    "    it = np.exp(-1*Emn)*AA\n",
    "    E = np.power(beta/(2*np.pi),N/2.0)*np.power(alpha/(2*np.pi),M/2.0)*it\n",
    "    return E\n",
    "\n",
    "    \n",
    "    \n",
    "x = np.arange(0,2*np.pi,.01)\n",
    "np.random.shuffle(x)\n",
    "y = gauss_sample(sin(x),1)\n",
    "pts = np.stack((x,y),axis=1)\n",
    "#def evidence_approx(x,y,n_bf,s,p,alpha,beta):\n",
    "a = 3\n",
    "b = 7\n",
    "p = 3\n",
    "s = .5\n",
    "n_bf = np.arange(1,11,1)\n",
    "m =[[np.zeros(1),np.zeros(2),np.zeros(3),\n",
    "               np.zeros(4),np.zeros(5),np.zeros(6),\n",
    "               np.zeros(7),np.zeros(8),np.zeros(9),\n",
    "               np.zeros(10)]]\n",
    "#cov = np.random.rand(10,10)\n",
    "\n",
    "\n",
    "#a,b = evidence_approx(x,y,n_bf,s,p,a,b)\n",
    "ab = []\n",
    "for i in range(0,10):\n",
    "    a = .3\n",
    "    b = .3\n",
    "    a,b = approx_alpha_beta(x,y,n_bf[i],s,p,a,b)\n",
    "    ab.append([a,b])\n",
    "\n",
    "print(ab)\n",
    "#evidence_approximation(pts,m,alpha,beta,n_bf,s,p)\n",
    "e = []\n",
    "for i in range(0,10):\n",
    "    ei = evidence_approximation(pts,ab[i][0],ab[i][1],n_bf[i],s,p)\n",
    "    e.append(ei)\n",
    "\n",
    "    \n",
    "print(e)\n",
    "plt.plot(n_bf,e)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
